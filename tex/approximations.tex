%!TEX root = ../DeGaulle.tex
\section{Approximations}

By an isotopic configuration we understand information about the number of different isotopes in the sample. For the purpose of simplicity, we focus here on chemical compounds composed of carbon, hydrogen, nitrogen, oxygen, and sulfur; still, the results of this section generalize to any compounds whatsoever. Thus, we concentrate on compounds like \molecule, where the low case letters describe the numbers of atoms of particular element type. Among such compounds one can already find peptides and proteins. An isotopic configuration could be represented by an extended empirical formula, 
\begin{equation}\label{long chemical formula}
	\text{\moleculeIsotopic}.
\end{equation}

In the above representation, small letters with indices represent counts of different atoms with indices displaying the number of additional neutrons an isotope has with respect to the lighest possible isotopic variant. 

Rather than \eqref{long chemical formula}, we shall be using an equivalent probabilistic notation, treating upper case letters, like \ce{^{12}C}, as random variables and considering small case letters, $\cem{c_0}$, to be their realisations. An expression like $A = \{ \ce{^{13}C} = \cem{c_1},\, \ce{^{2}H} = \cem{h_1} \}$ is shorthand for saying: let us focus on all configurations \eqref{long chemical formula} that have \ce{c_1} heavy carbons and \ce{h_1} deuters in total.


Following \cite{Kienitz1961MassSpectrometry}, one assumes that the law of vector
\begin{equation}\label{long chemical vector}
	\left( \cem{^{12}C},\, \cem{^{13}C},\, \cem{^{1}H},\, \cem{^{2}H},\, \cem{^{14}N},\, \cem{^{15}N},\, \cem{^{16}O},\, \cem{^{17}O},\, \cem{^{18}O},\, \cem{^{32}S},\, \cem{^{33}S},\, \cem{^{34}S},\, \cem{^{36}S} \right),	
\end{equation}
given \molecule, is a product of independent multinomial distributions,
{\small\begin{equation}\label{product of multinomials}
	\MM = \mathrm{Multi} \Big( \prob(\cem{^{12}C}), \prob(\cem{^{13}C}); c \Big)
	\otimes \dots \otimes 
	\mathrm{Multi} \Big( \prob(\cem{^{32}S}), \prob(\cem{^{33}S}), \prob(\cem{^{34}S}), \prob(\cem{^{36}S}); s \Big),	
\end{equation}}
where the probabilities of observing particular isotopes, $\prob(\cem{^{12}C})$, \dots, $\prob(\cem{^{36}S})$, are established in independent experiments\footnote{Consult Table \ref{basic info on isotopes table} for details.}. For instance, the probability of a given carbons configuration $(\cem{c_0}, \cem{c_1})$ equals
% \begin{equation*}
% 	\mathrm{Multi} \left( \prob(\cem{^{12}C}), \prob(\cem{^{13}C}); c \right)
% 		\Big( (\cem{c_0}, \cem{c_1}) \Big) = 
% 	\begin{pmatrix}
% 		\cem{c} \cr \cem{c_0}, \cem{c_1}  
% 	\end{pmatrix} \prob(\cem{^{12}C})^\cem{c_0} \prob(\cem{^{13}C})^\cem{c_1}
% \end{equation*}
$$
	\mathrm{Multi} \left( \prob(\cem{^{12}C}), \prob(\cem{^{13}C}); c \right)
		\Big( (\cem{c_0}, \cem{c_1}) \Big) = 
	\begin{pmatrix}
		\cem{c} \cr \cem{c_0}, \cem{c_1}  
	\end{pmatrix} \prob(\cem{^{12}C})^\cem{c_0} \prob(\cem{^{13}C})^\cem{c_1}
$$
and it should be multiplied by similar expression for hydrogen, nitrogen, oxygen and sulfur to obtain probability for expression like \eqref{long chemical formula}.


Observe, that given \molecule, part of the information in \eqref{long chemical vector} is redundant and can be shortened by neglecting counts of the lightest isotope variants, leaving us with 
\begin{equation}\label{short chemical vector}
 	\left( \cem{^{13}C},\, \cem{^{2}H},\, \cem{^{15}N},\, \cem{^{17}O},\, \cem{^{18}O},\, \cem{^{33}S},\, \cem{^{34}S},\, \cem{^{36}S} \right).	
\end{equation}
Missing therms can be retrieved from relationships $\cem{^{12}C} + \cem{^{13}C} = \cem{c}$, $\cem{^{1}H} + \cem{^{2}H} = \cem{h}$, and so on, that occur with probability one.

\begin{mydef}\label{localised fine structure definition}
	We call the set of configurations  
	{\small
		\begin{equation}\label{LFS_K}
			LFS_K	=
			\left\{ 
				\cem{^{13}C} + \cem{^{2}H} +  \cem{^{15}N} +  \cem{^{17}O} +  \cem{2 $\times$^{18}O} +  \cem{^{33}S} +  \cem{2 $\times$^{34}S} + \cem{4 $\times$^{36}S} = K	
			\right\}
		\end{equation}
	}
	a \emph{localised fine structure with $K$ extra neutrons}.  	
\end{mydef}

The reason for numbers 2 and 4 appearing above is that \ce{^{18}O} and \ce{^{34}S} have two additional neutrons, and \ce{^{36}S} -- four; confront Table \ref{basic info on isotopes table}.

The problem of finding the cardinal number of $LFS_K$ is also known as the money exchange problem. In general, enumeration of all elements of $LFS_K$ corresponds to finding all integer solutions $(x_1, \dots, x_k)$ to a {\it Linear Diophantine Equation}  
\begin{equation}\label{Linear Diophantine Equation}
	d_1 x_1 + \dots + d_k x_k = K,
\end{equation}
where $(d_1, \dots, d_k)$ are integer coefficients. According to \cite{Agnarsson2002OnTheSylvesterDenumerants}, if the greatest common divisor of $(d_1, \dots, d_k)$ is equal to one, then the number of solutions to \eqref{Linear Diophantine Equation} is approximately $\frac{K^{k-1}}{(k-1)! d_1 \dots d_k}$. Carbon has only one addtional isotope, so $\exists_i d_i = 1$ in \eqref{Linear Diophantine Equation}. The above estimate encompases therefore all of organic chemistry. 

The problem is big, being polynomial in $K$. Nevertheless, configurations in $LFS_K$ are naturally prioritized by probability \eqref{product of multinomials}. Rather than enumerating them all, one can be satisfied with only the most probable ones. 

%  is simply a subset of all possible configurations \eqref{long chemical formula} with additional constraint 
% \begin{equation}\label{Simple Diophantine Equation}
% 	\cem{c_1} + \cem{h_1} + \cem{n_1} + \cem{o_1} + 2 \cem{o_2} + \cem{s_1} + 2 \cem{s_2} + 4 \cem{s_4} = K.
% \end{equation}

\begin{Problem}\label{Problem of finding LFS_K configurations.}
	For a given $K$, find a small set $B \subset LFS_K$ of configurations s.t. 
	\begin{equation}\label{problem equation}
		\MK (B) := \frac{ \MM(B) }{ \MM( LFS_K ) } \approx 1\,,	
	\end{equation} 
	where $\MK$ is the product of multinomial laws \eqref{product of multinomials} conditional on the set of configurations in $LFS_K$ and is refered to as \emph{The Law of Localised Fine Structure}.
\end{Problem}


In statistical terms, we are interested in approximating some critical set of large probability, as measured by the {\it Law of Localised Fine Structure}. 


Why should one study law described by \eqref{problem equation} in the first place? Simply because the masses of different configurations in $LFS_K$ concentrate around the compound's monoisotopic mass shifted to the right by $K$ Daltons\footnote{For underlying physical principles consult \cite{Hughey2001KendrickMassDefect}.}. For medium sized compounds, $LFS_K$'s for different $K$ should in principle form disjoint clusters in the mass to charge domain, as argued in manuscript \cite{Dittwald2014OnTheFineIsotopicDistribution}; for bigger compounds some interference would be expected, but in that case one would simply study three or more consecutive sets of configurations, e.g. $LFS_{K-1}$, $LFS_K$, and $LFS_{K+1}$. All in all, by studying $LFS_K$ we get a guarantee to explore thoroughly a precised place in the mass to charge domain. More reasons behind this idea are exposed in the \textbf{Conclusions and Discussion} section. 


To solve Problem \ref{Problem of finding LFS_K configurations.} we approximate measure $\MK$ by a more analytically tractable measure $\QK$ defined on the $LFS_K$. We then devise an algorithm to find a possibly small set of configurations $B^* \subset LFS_K$, s.t. $\QK (B^*) \approx 1$. Since $\QK \approx \MK$, so $\MK (B^*) \approx 1$ and $B^*$ solves Problem \ref{Problem of finding LFS_K configurations.}, possibly suboptimally.


A natural way to define proper $\QK$ is to first approximate $\MM$ by some $\QQ$ and then pose $\QK (\circ) := \frac{\QQ (\circ \cap LFS_K) }{\QQ(LFS_K)}$, i.e. condition $\QQ$ on the occurence of configurations from $LFS_K$. To prove it works, we have to first mention, that by approximation we understand convergence in distribution, as described in \cite{Kallenberg2002FoundationsOfModernProbability}. Then, we make use of the following lemma: 

\begin{lemma}\label{conditional convergence lemma}
	Let $\mu^{[n]}, \mu$ be discrete measures. If $\mu^{[n]}$ converges in distribution to $\mu$, $\mu^{[n]} \rightharpoonup  \mu$, and an event $A$ has nonzero probability under any of that measures, $\underset{n}{\forall} \mu^{[n]}(A)\,,\, \mu(A) > 0$, then measures conditioned by $A$, $\mu^{[n]}_A (\circ) := \frac{\mu^{[n]} ( \circ \cap A)}{\mu^{[n]}(A)}$ converge in distribution to $\mu_A (\circ) := \frac{ \mu( \circ \cap A) }{ \mu(A) }$; or $\mu^{[n]}_A \rightharpoonup \mu_A$ for short.
\end{lemma}  
The proof is exposed in the \textbf{Appendix}.  


Let us now unveil the usefulness of Lemma \ref{conditional convergence lemma}. There is an entire family of measures mentioned in it, $\mu^{[n]}$. We assume, that one of them is simply our initial meausure: there exists $n^*$ s.t. $\MM = \mu^{[n^*]}$. Also, we assume the approximation of $\mu^{[n^*]}$ by measure $\mu$ is already o good one. Our choice for $\mu$ is to be the product of independent Poisson measures, which is stimulated by the following, well known lemma\footnote{ The proof is common knowledge and we omit it.}.


\begin{lemma}\label{weak convergence of multinomial to Poissons lemma}
	If all\,\,$\lim_{n\to \infty} n p_{k,n}= \lambda_k$ exist for $k \in \{1,\dots, w\}$, then 
	
	\begin{equation}\label{weak convergence of multionial to Poissons equation}
		\mathrm{Multi}\left( p_0^{[n]}, p_1^{[n]}, \dots, p_w^{[n]}; n \right) 
			\rightharpoonup 
		\mathrm{Poiss}( \lambda_1) \otimes \dots \otimes \mathrm{Poiss}( \lambda_w ),	
	\end{equation}
	where $\mathrm{Poiss}$ stands for the Poisson distribution, $\mathrm{Poiss}(\lambda)(k) 	= \frac{\lambda^k}{k!}e^{-\lambda}$.
	
\end{lemma}


In Lemma \ref{weak convergence of multinomial to Poissons lemma} one assumes that the number of trials $n$ goes to infinity. In our model this corresponds to an infinite enlargement of the compound. The existence of limits assumes that this enlargement is done so that on such an idealized compound only the lightest isotopes would appear infinitely often. Moreover, since the support of any Poisson distibution is equal to the set of all integer numbers, the state space of configurations gets significantly enlarged and contains configurations that are nonphysical for any real chemical compound. For instance, positive probabilities would be prescribed to configurations with numbers of isotopes greater then the number of possible places for them on any finite compound\footnote{There is no mathematical incongruence here, however, since the approximation assumes that the limiting compound is of infinite size. For mathematical correctness we also note, that we can transfer virtually any initial measure $\MM$ on the enlarged state space, i.e. where the approximation is defined, simply by assuming, that $\MM$ measure on any nonphysical configuration equals zero.}. Observe also, that the probabilities $p_k^{[n]}$ are pending towards zero: for good approximation one would expect therefore the probabilities of observing heavier isotopes, e.g. quantities like $\prob(\cem{^{13}C}), \prob(\cem{^{2}H}), \dots, \prob(\cem{^{36}S})$, to be relatively small. Confront Table \ref{basic info on isotopes table} to check, that this is really the case.


Observe, that Lemma \ref{weak convergence of multinomial to Poissons lemma} defines a proper limit for just one multinomial distribution, whereas $\MM$ is a product thereof. The problem is other than what to do with products: one can approximate independently each multinomial. However, the quality of such approximation depends on all the counts of different elements in a molecule. For instance, in case of \molecule\,the better the approximation\footnote{The {\it goodness} of approximation is expressed in the total variance distance; see \cite{Roos1999OnTheRateOfMultivariatePoissonConvergence}.} the bigger the smallest among numbers $(\cem{c}, \cem{h}, \cem{n}, \cem{o}, \cem{s})$. Due to the polymer structure, one would expect some more information could be reveiled on that matter for proteins and peptides. Indeed, empirical research by Senko et al. \cite{Senko1995Determination} established the concept of avergine, i.e. an averaged protein: any protein composed of $m$ amino acids should have its mass approximately equal to the mass of the idealised compound 
\begin{equation*}
	\cem{C}_{\lfloor m \times 4.9384\rfloor} 
	\cem{H}_{\lfloor m \times 7.7583\rfloor} 
	\cem{O}_{\lfloor m \times 1.4773\rfloor} 	
	\cem{N}_{\lfloor m \times 1.3577\rfloor} 
	\cem{S}_{\lfloor m \times 0.0417\rfloor}.
\end{equation*}

The weakest link in the approximation might result from small numbers of sulfur. This is an acknowledged problem in empirical studies, as exposed in \cite{Valkenborg2007UsingPoisson}. The longer the polymers however, the smaller the differences should be. 


The final questions is: what values should be used as $\lambda$'s in Lemma \ref{weak convergence of multinomial to Poissons lemma}? We {\it calibrate} those values by equating them to the averages of the multinomial distributions from \eqref{product of multinomials}\footnote{Such {\it calibration} is common practice in statistics.}: in case of carbon we set $\lambda_\cem{^{13}C} \approx \cem{c} \times \prob( \cem{^{13}C} )$.  In contrast to our method, $\lambda$'s in \cite{Breen2000AutomaticPeak,Valkenborg2007UsingPoisson} are chosen to be the minimisers in a free parameter optimisation scheme with $\chi^2$ penalty\footnote{Note however, that these two solutions should not differ too much for larger compounds, for it is known that both the Poisson and Multinomial distributions are concentrated near their means, see \cite{Bobkov1998OnModifiedLogarithmicSobolev}.}. 


At days end, the probability assigned to event
\begin{equation*}
 	\left\{ \cem{^{13}C} = \cem{c_1},\, \cem{^{2}H} = \cem{h_1},\, \cem{^{15}N} = \cem{n_1},\, \cem{^{17}O} = \cem{o_1},\, \cem{^{18}O} = \cem{o_2},\, \cem{^{33}S} = \cem{s_1},\, \cem{^{34}S} = \cem{s_2},\, \cem{^{36}S}= \cem{s_4} \right\}	
\end{equation*} 
is given by
\begin{equation}\label{QK Nominator}
	\poiss{\text{c}}{13}{1}
	\poiss{\text{h}}{2}{1}
	\poiss{\text{n}}{15}{1}
	\poiss{\text{o}}{17}{1}
	\poiss{\text{s}}{33}{1}
		e^{ - \mu}
	\poiss{\text{o}}{18}{2}	
	\poiss{\text{s}}{34}{2}
		e^{ - \eta }		
	\poiss{\text{s}}{36}{1}
		e^{ - \gamma },
\end{equation}
where 
\begin{align*}\label{intensities summed equation}
	\mu 	&=	\lambda_\cem{^{13}C} + \lambda_\cem{^{2}H} + \lambda_\cem{^{15}N} + \lambda_\cem{^{17}O} +\lambda_\cem{^{33}S}  	\\
	\eta 	&= 	\lambda_\cem{^{18}O} + \lambda_\cem{^{34}S}\\ 
	\gamma	&= 	\lambda_\cem{^{36}S}.
\end{align*}

The usefulness of approximation by a product of independent Poisson lies in two important properties, as summarised in the following lemmas.

\begin{lemma}\label{sum of independent Poissons lemma}
	Suppose we have a collection of $m$ independent Poisson-distributed random variables, $X_i \sim \mathrm{Poiss}(\kappa_i)$. Then $X_1 + \dots + X_m \sim \mathrm{Poiss}(\kappa_1 + \dots + \kappa_m)$. 
\end{lemma}  

\begin{lemma}\label{Poisson conditional on sum of Poissons}
	Suppose we have a collection of $m$ independent Poisson-distributed random variables, $X_i \sim \mathrm{Poiss}(\kappa_i)$. Then $X_1, \dots, X_m$ given that $X_1 + \dots + X_m = K$ is multinomially distributed,

$$ 
	\Big(X_1, \dots, X_m | X_1 + \dots + X_m = K \Big) 
	\sim 
	\mathrm{Multi}\Big( \frac{\kappa_1}{\sigma}, \dots, \frac{\kappa_m}{\sigma}; K \Big), 
$$
	where $\sigma = \sum_{i = 1}^m \kappa_i$.	
\end{lemma}
Both lemmas are proved in \cite{Kingman1993PoissonProcesses}. Lemma \ref{sum of independent Poissons lemma} shows how to semplify calculations for a Diophantine equations with all parameters set to one, $a_i \equiv 1$. Lemma \ref{Poisson conditional on sum of Poissons} describes the law resulting from conditioning independent Poisson variables by such an expression. 

Suppose that we concentrated on molecules composed entirely of elements that can have only one additional neutron, e.g. \smallMolecule. By Lemma \ref{Poisson conditional on sum of Poissons} we get:

\begin{result}\label{Multinomial Result}
 	For \smallMolecule, let $\tilde{\mu} := \lambda_\cem{^{13}C} + \lambda_\cem{^{2}H} + \lambda_\cem{^{15}N}$. Then
 	$$\QK = \mathrm{Multi}\left(
 		\frac{\lambda_\cem{^{13}C}}{\tilde{\mu}}, 
 		\frac{\lambda_\cem{^{2}H}}{\tilde{\mu}}, 
 		\frac{\lambda_\cem{^{15}N}}{\tilde{\mu}}; K \right).$$
\end{result}

\begin{proof}
	The corresponding Diophantine equation is $\cem{^{13}C} + \cem{^2H} + \cem{^{15}N}$.
\end{proof}

It is valuable to see, how Lemma \ref{Poisson conditional on sum of Poissons} generalizes while conditioning on a more complex Diophantie equation. Observe, that \eqref{LFS_K} can be rewritten as 
\begin{equation*}
	LFS_K = \Big\{ \underbrace{\cem{^{13}C} + \cem{^2H} + \cem{^{15}N} + \cem{^{17}O} + \cem{^{33}S}}_{ G_1 } + \,2 \times \underbrace{( \cem{^{18}O} + \cem{^{34}S} )}_{ G_2 } + \,4 \times \underbrace{\cem{^{36}S}}_{ G_4 } = K \Big\},	
\end{equation*}
so that in light of Lemma \ref{sum of independent Poissons lemma}, $\QQ(A)$ can be calculated in an easier way: 
$$\QQ( LFS_K ) = \sum_{k_1 + 2 k_2 + 4 k_4 = K} \prob( G_1 = k_1, G_2 = k_2, G_4 = k_4 ),$$
where $G_1 \sim \mathrm{Poiss}( \mu )$, $G_2 \sim \mathrm{Poiss}( \eta )$, and $G_4 \sim \mathrm{Poiss}( \gamma )$ are mutually independent. There is a strict link between $G_i$ and the concept of {\it equatransneutronic groups} described in \cite{Olson2009Calculations}: it is equal to the total number of atoms bearing exactly $i$ additional neutrons.  

To calculate $\QK$ it remains to divide \eqref{QK Nominator} by $\QQ( LFS_K )$. Observe however that a more significant expression is to be obtained, if additionally we multiply both the nominator and the denominator of that expression by $\frac{\mu^{k_1}}{k_1 !} \frac{\eta^{k_2}}{k_2 !} \frac{\gamma^{k_4}}{k_4 !}$:

% Note also, that 
% \begin{align*}
% 	x 	& = \cem{c_1} + \cem{h_1} + \cem{n_1} + \cem{o_1} + \cem{s_1}, \\	  	
% 	y 	& = \cem{o_2} + \cem{s_2}, 	\\
% 	z 	& = \cem{s_4}.
% \end{align*}
% In \cite{Olson2009Calculations} they are encoded by $k_1, k_2$, and $k_4$; also, $d_{G_i} = i$. Then it is true that

\begin{result}\label{Fine structure law}
	The approximative \emph{fine structure law} with $K$ additional neutrons for \molecule\, is equal to 
	{\small
		\begin{equation*}
			\mathrm{Multi} \left(
				\frac{ \lambda_\cem{^{13}C} }{ \mu }, 
				\frac{ \lambda_\cem{^{2} H} }{ \mu }, 
				\frac{ \lambda_\cem{^{15}N} }{ \mu },
				\frac{ \lambda_\cem{^{17}O} }{ \mu }, 
				\frac{ \lambda_\cem{^{33}S} }{ \mu }; 
				k_1
			\right ) \otimes
			\mathrm{Multi} \left(
				\frac{ \lambda_\cem{^{18}O} }{ \eta },
				\frac{ \lambda_\cem{^{34}S} }{ \eta }; 
				k_2	
			\right) \otimes 
			\mathbb{L}( k_1, k_2, k_4 ),
		\end{equation*}
	}
	where 
	\begin{equation}\label{simple lucky law}
		\mathbb{L}( k_1, k_2, k_4 ) = 
		\frac{ \frac{ \mu^{k_1} }{ k_1! } \frac{ \eta^{k_2}}{ k_2! } \frac{ \gamma^{k_4} }{ k_4! } }{ 
			\underset{ k_1' + 2 k_2' + 4 k_4' = K}{\sum} 
				\frac{ \mu^{k_1'} }{ k_1'! } 
				\frac{ \eta^{k_2'}}{ k_2'! } 
				\frac{ \gamma^{k_4'}}{ k_4'! }
		}.
	\end{equation}
\end{result}

Otherwise stated, the approximative distribution is a mixture of independent multinomial distributions weighted by the $\mathbb{L}$ distribution, which, for lack of name, we shall call the {\it lucky law}. Under the Poisson approximation, the {\it lucky law} is the resulting law on the {\it equatransneutronic configurations}.

If the compound contains elements with their {\it additional neutron acceptances} in set $I = \{ 1, 2, 4\}$, formula \eqref{simple lucky law} generalizes to 
\begin{equation*}
	\mathbb{L}( \bm{k} ) = 
	\frac{ 
		\prod_{i \in I} \frac{ \mu_i^{k_i} }{ {k_i}! } 
	}{ 
		\underset{ \{ \bm{k}^* :  \sum_{i \in I} i k_i^*  = K \} }{\sum} 	
		\prod_{i \in I} \frac{ \mu_i^{k_i^*} }{ {k_i^*}! }	
	},
\end{equation*}
where $\bm{k}$ is an ordered tuple indexed by $I$. Nature poses a natural limit on the complexity of the {\it lucky law}, as at most  $\# I \leq 10$\todo{Ascertain that asking Frederik.}.