%!TEX root = ../DeGaulle.tex
\section*{Appendix}

\subsection*{Proof of Lemma \ref{conditional convergence lemma}}

We want to prove that if $\mu^{[n]} \rightharpoonup \mu$ and $\mu^{[n]}(A), \mu(A) > 0$, then also $\mu^{[n]}_A \rightharpoonup \mu_A$. We do this under the assumption that both $\mu^{[n]}$ and $\mu$ are discrete measures on probability space $E$. 

By the {\it Portmanteau Lemma}, see \cite{Kallenberg2002FoundationsOfModernProbability}, $\mu^{[n]} \rightharpoonup \mu$ implies that for any set $A$ with boundry $\partial A$ subject to $\mu( \partial A) = 0$, one should observe 

\begin{equation}\label{convergence in probability on good sets}
	\lim_{n \to \infty} \mu^{[n]}(A) = \mu(A).
\end{equation}


The notion of boundry requires the notion of topology: thus, we decide on the discrete topology, which is natural in this context \footnote{For appropriate topological notions consult \cite{Dugundji1966Topology}.}. In this topology however, $\partial A = \emptyset$, for it is a set theoretical difference of the closure and the interior, both of which are equal to $A$. Hence, $\mu( \partial A) = 0$. Thus, \eqref{convergence in probability on good sets} always holds.

{\it Ex definitione}, $\mu^{[n]} \rightharpoonup \mu$ means, that for any bounded function $f:E\to\mathbb{R}$ one observes
\begin{equation}\label{weak convergence definition}
	\int f \mathrm{d} \mu^{[n]} \underset{n \to \infty}{\xrightarrow{\hspace*{1cm}}} \int f \mathrm{d}\mu\,.
\end{equation}

A simple calculation using both \eqref{convergence in probability on good sets} and \eqref{weak convergence definition} completes the proof:

\begin{equation*}
	\int f \mathrm{d} \mu^{[n]}_A =  \frac{ \int f \mathrm{d} \mu^{[n]} }{ \mu^{[n]}(A) } \underset{n \to \infty}{\xrightarrow{\hspace*{1cm}}} \frac{ \int f \mathrm{d} \mu }{ \mu(A) } = \int f \mathrm{d} \mu\,.
\end{equation*}

\subsection*{General form of the \emph{Lucky Law}}

If the compound contains elements with their {\it additional neutron acceptances} in set $I = \{ 1, 2, 4\}$, formula \eqref{simple lucky law} generalizes to 
\begin{equation*}
	\mathbb{L}( \bm{k} ) = 
	\frac{ 
		\prod_{i \in I} \frac{ \mu_i^{k_i} }{ {k_i}! } 
	}{ 
		\underset{ \{ \bm{k}^* :  \sum_{i \in I} i k_i^*  = K \} }{\sum} 	
		\prod_{i \in I} \frac{ \mu_i^{k_i^*} }{ {k_i^*}! }	
	},
\end{equation*}
where $\bm{k}$ is an ordered tuple indexed by $I$. Nature poses a natural limit on the complexity of the {\it lucky law}, as at most  $\# I \leq 10$\todo{Ascertain that asking Frederik.}.


\subsection*{Obtaining $M\%$ critical sets of the Multinomial Distribution}

We achieve this by controlled {\it breadth first search}: the configurations of the multinomial distribution can be thought of vertices $V$ of an underlying graph, $G = (V,E)$. Two configurations $\bm{v}, \bm{w} \in V$ define an edge $(\bm{v}, \bm{w}) \in E$ if and only if $\exists_{i \not= j} v_i = w_i + 1$ and $v_j = w_j - 1$. One then starts the algoritm in the vicinity of the mode of current $\mathrm{Multi}\left( p_1, \dots, p_w; n \right)$: as proxy, we use the point with coordinates equal to the floor of $n p_i + 1$. More elaborate set of candidates can be used, see \cite{Gall2003DeterminationOfTheModesOfMultinomial}. One then enlists all the neighbours of the initial node and puts the on a {\it max-priority queue}, see \cite{Cormen2001IntroductionToAlgorithms}. One then recursively looks at neighbours of the top-priority configuration, checks their probabiliy and enqueues them. In the same time, using a hash-table, one must store information on the visited configurations to avoid multiple visits to the same node. Observe that in case of molecules containing elements with only one isotope, e.g. \smallMolecule, this step alone would suffice to solve the problem, as showed in Result \ref{Multinomial Result}.